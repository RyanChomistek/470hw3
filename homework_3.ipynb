{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 470 :: Information Storage and Retrieval :: Texas A&M University :: Fall 2018\n",
    "\n",
    "\n",
    "# Homework 3 (and 4):  Recommenders\n",
    "\n",
    "### 100 points [10% of your final grade; that's double!]\n",
    "\n",
    "### Due: November 8, 2018\n",
    "\n",
    "*Goals of this homework:* Put your knowledge of recommenders to work. \n",
    "\n",
    "*Submission Instructions (Google Classroom):* To submit your homework, rename this notebook as  `lastname_firstinitial_hw#.ipynb`. For example, my homework submission would be: `caverlee_j_hw3.ipynb`. Submit this notebook via **Google Classroom**. Your IPython notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Movielens Data\n",
    "\n",
    "For this first part, we're going to use part of the Movielens 100k dataset. Prior to the Netflix Prize, the Movielens data was **the** most important collection of movie ratings.\n",
    "\n",
    "First off, we need to load the data (including u.user, u.item, and ua.base). Here, we provide you with some helper code to load the data using [Pandas](http://pandas.pydata.org/). Pandas is a nice package for Python data analytics.\n",
    "\n",
    "You may need to install pandas doing something like:\n",
    "\n",
    "`conda install --name cs470 pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieId</th>\n",
       "      <th>Title</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieId              Title  UserId  Rating  Age Gender  Occupation ZipCode\n",
       "0        1   Toy Story (1995)       1       5   24      M  technician   85711\n",
       "1        2   GoldenEye (1995)       1       3   24      M  technician   85711\n",
       "2        3  Four Rooms (1995)       1       4   24      M  technician   85711\n",
       "3        4  Get Shorty (1995)       1       3   24      M  technician   85711\n",
       "4        5     Copycat (1995)       1       3   24      M  technician   85711"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the user data\n",
    "users_df = pd.read_csv('u.user', sep='|', names=['UserId', 'Age', 'Gender', 'Occupation', 'ZipCode'])\n",
    "\n",
    "# Load the movies data: we will only use movie id and title for this homework\n",
    "movies_df = pd.read_csv('u.item', sep='|', names=['MovieId', 'Title'], usecols=range(2), encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Load the ratings data: ignore the timestamps\n",
    "ratings_df = pd.read_csv('ua.base', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n",
    "\n",
    "# Working on three different data frames is a pain\n",
    "# Let us create a single dataset by \"joining\" these three data frames\n",
    "movie_ratings_df = pd.merge(movies_df, ratings_df)\n",
    "movielens_df = pd.merge(movie_ratings_df, users_df)\n",
    "\n",
    "movielens_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Let's find similar users [20 points]\n",
    "\n",
    "Before we get to the actual task of building our recommender, let's familiarize ourselves with the Movielens data.\n",
    "\n",
    "Pandas is really nice, since it let's us do simple aggregates. For example, we can find a specific user and take a look at that user's ratings. For example, for the user with user ID = 363, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23594</th>\n",
       "      <td>363</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>87501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserId  Age Gender Occupation ZipCode\n",
       "23594     363   20      M    student   87501"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = movielens_df.groupby('UserId')\n",
    "User363 = gb.get_group(363)\n",
    "#the information for the user\n",
    "User363[:1][[\"UserId\", \"Age\", \"Gender\",\"Occupation\", \"ZipCode\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23594</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23595</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23596</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23597</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23598</th>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23600</th>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23601</th>\n",
       "      <td>Seven (Se7en) (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23602</th>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23603</th>\n",
       "      <td>From Dusk Till Dawn (1996)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  Rating\n",
       "23594            Toy Story (1995)       2\n",
       "23595            GoldenEye (1995)       4\n",
       "23596           Get Shorty (1995)       5\n",
       "23597              Copycat (1995)       1\n",
       "23598       Twelve Monkeys (1995)       3\n",
       "23599                 Babe (1995)       5\n",
       "23600     Dead Man Walking (1995)       3\n",
       "23601        Seven (Se7en) (1995)       5\n",
       "23602  Usual Suspects, The (1995)       5\n",
       "23603  From Dusk Till Dawn (1996)       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then we can see his first 10 ratings:\n",
    "User363[['Title', 'Rating']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balderdash! Everyone agrees that Toy Story should be rated 5! Oh well, there's no accounting for taste.\n",
    "\n",
    "Moving on, let's try our hand at finding similar users to this base user (user ID = 363). In each of the following, **find the top-10 most similar users** to this base user. You should use all of the user's ratings, not just the top-10 like we showed above. We're going to try different similarity methods and see what differences arise.\n",
    "\n",
    "You should implement each of these similar methods yourself! \n",
    "\n",
    "###     Top-10 Most Similar Users Using\n",
    "#### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#setup ratings matrix\n",
    "\n",
    "def getRatingMatrix(ratingsDf):\n",
    "    matrix = np.zeros([ratingsDf['UserId'].max()+1, ratingsDf['MovieId'].max()+1])\n",
    "    print(ratingsDf['UserId'].max()+1, ratingsDf['MovieId'].max()+1)\n",
    "    gb = ratingsDf.groupby('UserId')\n",
    "    for userId, group in gb:\n",
    "        for mindex, mRow in group.iterrows():\n",
    "            movieId = mRow['MovieId']\n",
    "            matrix[userId][movieId] = int(mRow['Rating'])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1683\n"
     ]
    }
   ],
   "source": [
    "ratingMatrix= getRatingMatrix(movielens_df)\n",
    "ratingMatrixT = ratingMatrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276.0</td>\n",
       "      <td>0.392427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301.0</td>\n",
       "      <td>0.360577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>896.0</td>\n",
       "      <td>0.357588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>551.0</td>\n",
       "      <td>0.352814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>916.0</td>\n",
       "      <td>0.351111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>435.0</td>\n",
       "      <td>0.350806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>293.0</td>\n",
       "      <td>0.349901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864.0</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.344554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>417.0</td>\n",
       "      <td>0.344262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserId   jaccard\n",
       "275   276.0  0.392427\n",
       "300   301.0  0.360577\n",
       "895   896.0  0.357588\n",
       "550   551.0  0.352814\n",
       "915   916.0  0.351111\n",
       "434   435.0  0.350806\n",
       "292   293.0  0.349901\n",
       "863   864.0  0.344828\n",
       "91     92.0  0.344554\n",
       "416   417.0  0.344262"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard(user1Id, user2Id, matrix):\n",
    "    u1Vec = np.where(matrix[user1Id] > 0, 1, 0)\n",
    "    u2Vec = np.where(matrix[user2Id] > 0, 1, 0)\n",
    "    \n",
    "    intersection = (np.dot(u1Vec, u2Vec))\n",
    "    A = np.sum(u1Vec)\n",
    "    B = np.sum(u2Vec)\n",
    "    return intersection / (A + B - intersection) \n",
    "\n",
    "users_df_copy = users_df\n",
    "jaccard_df = users_df_copy.apply(lambda row: pd.Series(\n",
    "    {\n",
    "        'UserId': row['UserId'],\n",
    "        'jaccard': jaccard (363, row['UserId'], ratingMatrix)\n",
    "    }),axis=1)\n",
    "jaccard_df.sort_values('jaccard', ascending = False)[1:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276.0</td>\n",
       "      <td>0.603857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864.0</td>\n",
       "      <td>0.530819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>435.0</td>\n",
       "      <td>0.529115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303.0</td>\n",
       "      <td>0.522762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>429.0</td>\n",
       "      <td>0.522503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>896.0</td>\n",
       "      <td>0.518806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92.0</td>\n",
       "      <td>0.512386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>682.0</td>\n",
       "      <td>0.511880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497.0</td>\n",
       "      <td>0.510762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>222.0</td>\n",
       "      <td>0.510253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserId    cosine\n",
       "275   276.0  0.603857\n",
       "863   864.0  0.530819\n",
       "434   435.0  0.529115\n",
       "302   303.0  0.522762\n",
       "428   429.0  0.522503\n",
       "895   896.0  0.518806\n",
       "91     92.0  0.512386\n",
       "681   682.0  0.511880\n",
       "496   497.0  0.510762\n",
       "221   222.0  0.510253"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def normalize(vec):\n",
    "    magnitude = np.linalg.norm(vec)\n",
    "    return vec / magnitude\n",
    "\n",
    "def magnitude(vec):\n",
    "    return np.linalg.norm(vec)\n",
    "\n",
    "def cosine(user1Id, user2Id, matrix):\n",
    "    u1Vec = matrix[user1Id]\n",
    "    ANorm = magnitude(u1Vec)\n",
    "    u2Vec = matrix[user2Id]\n",
    "    BNorm = magnitude(u2Vec)\n",
    "    dot = np.dot(u1Vec, u2Vec)\n",
    "    return (dot / (ANorm*BNorm))\n",
    "    \n",
    "users_df_copy = users_df\n",
    "users_df_copy = users_df_copy[users_df_copy.UserId != 363]\n",
    "\n",
    "cosine_df = users_df_copy.apply(lambda row: pd.Series(\n",
    "    {\n",
    "        'UserId': row['UserId'],\n",
    "        'cosine': cosine(363,row['UserId'], ratingMatrix)\n",
    "    }),axis=1)\n",
    "cosine_df.sort_values('cosine', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the intersection we'll use in the next part\n",
    "#this seems a little more complicated than it needs to be, but its really slow otherwise\n",
    "def intersection(user1Id, user2Id, matrix):\n",
    "    #convert arrays to 1 or 0\n",
    "    u1Vec = np.where(matrix[user1Id] > 0, 1, 0)\n",
    "    u2Vec = np.where(matrix[user2Id] > 0, 1, 0)\n",
    "    \n",
    "    #find which elements both have 1's\n",
    "    intersect = np.logical_and(u1Vec, u2Vec)\n",
    "    \n",
    "    #find all values that were 0 in the intersect and make them 0 \n",
    "    u1Intersect = intersect * matrix[user1Id]\n",
    "    u2Intersect = intersect * matrix[user2Id]\n",
    "    \n",
    "    #remove all the zeros\n",
    "    return (np.extract(u1Intersect > 0, u1Intersect), np.extract(u2Intersect > 0, u2Intersect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanc\\Anaconda3\\envs\\newcs470\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>220.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>242.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>685.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>732.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>662.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>341.0</td>\n",
       "      <td>0.992129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>736.0</td>\n",
       "      <td>0.959680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserId   pearson\n",
       "219   220.0  1.000000\n",
       "241   242.0  1.000000\n",
       "684   685.0  1.000000\n",
       "731   732.0  1.000000\n",
       "154   155.0  1.000000\n",
       "661   662.0  1.000000\n",
       "281   282.0  1.000000\n",
       "139   140.0  1.000000\n",
       "340   341.0  0.992129\n",
       "735   736.0  0.959680"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def pearson(user1Id, user2Id, matrix):\n",
    "    '''\n",
    "    This is the pearson from the slides\n",
    "    '''\n",
    "    (u1Vec, u2Vec) = intersection(user1Id, user2Id, matrix)\n",
    "    u1Mean = np.mean(np.extract(matrix[user1Id] > 0, matrix[user1Id]))\n",
    "    u2Mean = np.mean(np.extract(matrix[user2Id] > 0, matrix[user2Id]))\n",
    "    u1Diff = (u1Vec - u1Mean)\n",
    "    u2Diff = (u2Vec - u2Mean)\n",
    "    covariance = (u1Diff * u2Diff).sum()\n",
    "    bottom = math.sqrt((u1Diff*u1Diff).sum()*(u2Diff*u2Diff).sum())\n",
    "    return covariance / bottom\n",
    "\n",
    "users_df_copy = users_df\n",
    "users_df_copy = users_df_copy[users_df_copy.UserId != 363]\n",
    "\n",
    "pearson_df = users_df_copy.apply(lambda row: pd.Series(\n",
    "    {\n",
    "        'UserId': row['UserId'],\n",
    "        'pearson': pearson (363, row['UserId'], ratingMatrix)\n",
    "    }),axis=1)\n",
    "\n",
    "pearson_df.sort_values('pearson', ascending = False)[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences among these three similarity methods? Which one do you prefer, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Jaccard does not care about the rating that the user gave, only that it is included in the set of movies they rated, This causes it to maybe not be the best because it doesent take into account whether a user actually liked the movie. Cosine is better because it takes into account the rating, but it counts all of the movies that a user hasent rated but the other has as a 0, this may not be an accurate representation of a users score for that movie since they may have just not seen it yet. Pearson I think is the best because it takes into account ratings, and doesn't assume as much as cosine, because it only looks at movies that both have rated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: User-User Collaborative Filtering: Similarity-Based Ratings Prediction [20 points]\n",
    "\n",
    "Now let's estimate the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97) based on the similar users. Find the 10 nearest (most similiar by using Pearson) users who rated the movie \"Dances with Wolves (1990)\" and try different aggregate functions. Recall, there are many different ways to aggregate the ratings of the nearest neighbors. We'll try three popular methods:\n",
    "\n",
    "### Method 1: Average. \n",
    "The first is to simply average the ratings of the nearest neighbors:\n",
    "$r_{c,s} = \\frac{1}{N}\\sum_{c'\\in \\hat{C}}r_{c',s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted score =  3.6\n"
     ]
    }
   ],
   "source": [
    "def getClosestkSimilarUsers(movieId, userId, similarityFunc, k, matrix, matrixT):\n",
    "    usersWhoSawMovie = np.where(matrixT[movieId] > 0, 1, 0)\n",
    "    #userIndexes is just [1,2,3,...,n]\n",
    "    userIndexes = np.fromfunction(lambda i,j: j, (1,len(usersWhoSawMovie)), dtype=int)[0]\n",
    "    usersWhoSawMovieIndexes = (usersWhoSawMovie * userIndexes)\n",
    "    usersWhoSawMovieIndexesFiltered = np.extract(usersWhoSawMovieIndexes > 0, usersWhoSawMovieIndexes)\n",
    "    \n",
    "    usersWithSim = (np.array(list(\n",
    "        map(lambda item2: \n",
    "            (item2, similarityFunc (userId, item2, matrix), matrix[item2][movieId]),\n",
    "             usersWhoSawMovieIndexesFiltered))))\n",
    "    usersWithSim = np.nan_to_num(usersWithSim,0)\n",
    "    if(len(usersWithSim) is 0):\n",
    "        print(movieId, userId)\n",
    "        return pd.DataFrame(data = [[0,0,0]], columns= ['UserId', 'similarity', 'Rating'])\n",
    "    sortedTopK = usersWithSim[usersWithSim[:,1].argsort()[::-1]][:k]\n",
    "    return pd.DataFrame(data = sortedTopK, columns= ['UserId', 'similarity', 'Rating'])\n",
    "\n",
    "print('predicted score = ', getClosestkSimilarUsers(97,363, pearson, 10, ratingMatrix, ratingMatrixT)['Rating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Weighted Average 1. \n",
    "The second is to take a weighted average, where we weight more \"similar\" neighbors higher: $r_{c,s} = k\\sum_{c'\\in \\hat{C}}sim(c, c')\\times r_{c',s}$\n",
    "\n",
    "Choose a reasonable k so that r_{c,s} is between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted score =  3.563047602289183\n"
     ]
    }
   ],
   "source": [
    "def weightedAverage(movieId, userId, similarityFunc, k, matrix, matrixT):\n",
    "    closestk = getClosestkSimilarUsers(movieId,userId, similarityFunc, k, matrix, matrixT)\n",
    "    k = 1/closestk['similarity'].sum()\n",
    "    score = closestk.apply(lambda row: k * row['similarity'] * row['Rating'], axis=1).sum()\n",
    "    return score\n",
    "\n",
    "print('predicted score = ', weightedAverage(97, 363, pearson, 10, ratingMatrix, ratingMatrixT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Weighted Average 2. \n",
    "An alternative weighted average is to weight the differences between their ratings and their average rating (in essence to reward movies that are above the mean): $r_{c,s} = \\bar{r}_c + k\\sum_{c'\\in \\hat{C}}sim(c, c')\\times (r_{c',s} - \\bar{r}_{c'})$\n",
    "\n",
    "Choose a reasonable k so that r_{c,s} is between 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted score =  2.8008842673651237\n"
     ]
    }
   ],
   "source": [
    "def weightedAverage2(movieId, userId, similarityFunc, k, matrix,matrixT):\n",
    "    closestk = getClosestkSimilarUsers(movieId,userId, similarityFunc, k, matrix, matrixT)\n",
    "    k = 1/closestk['similarity'].sum()\n",
    "    rMean = np.mean(np.extract(matrix[userId] > 0, matrix[userId]))\n",
    "    def innerSum(row):\n",
    "        rUserId = int(row['UserId'])\n",
    "        rOtherMean = np.mean(np.extract(matrix[rUserId] > 0, matrix[rUserId]))\n",
    "        return row['similarity'] * (row['Rating'] - rOtherMean)\n",
    "    score = rMean + k * closestk.apply(innerSum, axis=1).sum()\n",
    "\n",
    "    return score\n",
    "\n",
    "print('predicted score = ', weightedAverage2(97, 363, pearson, 10, ratingMatrix, ratingMatrixT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Baseline Recommendation (Global) [20 points]\n",
    "\n",
    "OK, so far we've built the basics of a user-user collaborative filtering approach; that is, we take a user, find similar users and then aggregate their ratings. \n",
    "\n",
    "An alternative approach is to consider just basic statistics of the movies and users themselves. This is the essence of the \"baseline\" recommender we discussed in class:\n",
    "\n",
    "$b_{xi} = \\mu + b_x + b_i$\n",
    "\n",
    "where $b_{x,i}$ is the baseline estimate rating user x would give to item i, $\\mu$ is the overall mean rating, $b_x$ is a user bias term, and $b_i$ is an item bias term.\n",
    "\n",
    "For this part, let's once again estimate the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97), but this time using the baseline recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline for user 363, item 97 =  3.3047530007520427\n"
     ]
    }
   ],
   "source": [
    "def getBaseline(userId, itemId, matrix, matrixT, avgGlobal):\n",
    "    #we ask them to give us the global because it takes a long time to calculate\n",
    "    start = time.time()\n",
    "    #avgGlobal = np.extract(matrix > 0, matrix).mean()\n",
    "    avgUser = np.extract(matrix[userId] > 0, matrix[userId]).mean()\n",
    "    avgMovie = np.extract(matrixT[itemId] > 0, matrixT[itemId]).mean()\n",
    "    end = time.time()\n",
    "    #print(end - start)\n",
    "    #print(avgGlobal + (avgUser - avgGlobal) + (avgMovie - avgGlobal))\n",
    "    return avgGlobal + (avgUser - avgGlobal) + (avgMovie - avgGlobal)\n",
    "\n",
    "avgGlobal = np.extract(ratingMatrix > 0, ratingMatrix).mean()\n",
    "print('baseline for user 363, item 97 = ', getBaseline(363, 97, ratingMatrix, ratingMatrixT, avgGlobal))\n",
    "#avgGlobal = np.extract(trainingRatingMatrix > 0, trainingRatingMatrix).mean()\n",
    "#getBaseline(405, 1582, trainingRatingMatrix, trainingRatingMatrixT, avgGlobal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Local + Global Recommendation (Baseline + Item-Item CF) [20 points]\n",
    "\n",
    "Our final recommender combines the global baseline recommender with an item-item local recommender. \n",
    "\n",
    "$\\hat{r}_{xi} = b_{xi} + \\dfrac{\\sum_{j \\in N(i;x)}s_{ij} \\cdot (r_{xj} - b_{xj})}{\\sum_{j \\in N(i;x)}s_{ij}} $\n",
    "\n",
    "where \n",
    "* $\\hat{r}_{xi}$ is our estimated rating for what user x would give to item i.\n",
    "* $s_{ij}$ is the similarity of items i and j.\n",
    "* $r_{xj}$ is the rating of user x on item j.\n",
    "* $N(i;x)$ is the set of items similar to item i that were rated by x.\n",
    "\n",
    "You will need to make some design choices here about what similarity measure to use and what threshold to determine what items belong in $N(i;x)$.\n",
    "\n",
    "Now show us what this estimates the rating of UserID 363 for the movie \"Dances with Wolves (1990)\" (MovieId 97) to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemItemSim(userId, movieId, matrix, matrixT, similarityFunc):\n",
    "    #get the movies the user has seen as an array of 1s and 0s\n",
    "    moviesUserHasSeen = np.where(matrix[userId] > 0, 1, 0)\n",
    "    \n",
    "    #get an array of just indexes for the movies\n",
    "    movieIndexes = np.fromfunction(lambda i,j: j, (1,len(matrix[userId])), dtype=int)[0]\n",
    "    #change the 1s to be the index of the movie it represents, and filter 0s\n",
    "    moviesUserHasSeenIndexes = (moviesUserHasSeen * movieIndexes)\n",
    "    \n",
    "    moviesUserHasSeenFiltered = np.extract(moviesUserHasSeenIndexes > 0, moviesUserHasSeenIndexes)\n",
    "    \n",
    "    moviesWithSim = (np.array(list(map\n",
    "             (\n",
    "                lambda otherMovieId:\n",
    "                 (\n",
    "                    otherMovieId,\n",
    "                    similarityFunc(movieId, otherMovieId, matrixT),\n",
    "                    matrix[userId][otherMovieId]\n",
    "                ),\n",
    "                moviesUserHasSeenFiltered\n",
    "             ))))\n",
    "    moviesWithSim = np.nan_to_num(moviesWithSim,0)\n",
    "    \n",
    "    return moviesWithSim\n",
    "\n",
    "def itemItemAboveCutoff(userId, movieId, cutoff, matrix, matrixT, similarityFunc):\n",
    "    moviesWithSim = itemItemSim(userId, movieId, matrix, matrixT, similarityFunc)\n",
    "    sortedSim = moviesWithSim[moviesWithSim[:,1].argsort()[::-1]]\n",
    "    aboveCutoff = sortedSim[sortedSim[:,1] > cutoff]\n",
    "    return aboveCutoff\n",
    "\n",
    "def itemItemClosestK(userId, movieId, k, matrix, matrixT, similarityFunc):\n",
    "    moviesWithSim = itemItemSim(userId, movieId, matrix, matrixT, similarityFunc)\n",
    "    sortedTopK = moviesWithSim[moviesWithSim[:,1].argsort()[::-1]][:k]\n",
    "    \n",
    "    return pd.DataFrame(data = sortedTopK, columns= ['MovieId', 'similarity', 'Rating'])\n",
    "\n",
    "ratingMatrixT = ratingMatrix.transpose()\n",
    "#itemItemSim(363, 97, ratingMatrix, ratingMatrixT, jaccard)\n",
    "#itemItemClosestK(363, 97, 10, ratingMatrix, ratingMatrixT, jaccard)\n",
    "#itemItemAboveCutoff(363, 97, .4, ratingMatrix, ratingMatrixT, jaccard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020987510681152344\n",
      "2.975832955419648\n"
     ]
    }
   ],
   "source": [
    "def localRating(userId, movieId, ratingsDf, matrix, matrixT, avgGlobal, k, similarityFunc):\n",
    "    start = time.time()\n",
    "    gb = ratingsDf.groupby('UserId')\n",
    "    top = 0\n",
    "    bot = 0\n",
    "    for mIndex, mRow in itemItemClosestK(userId, movieId, k, matrix, matrixT, similarityFunc).iterrows():\n",
    "        sim = mRow['similarity']\n",
    "        bot += sim\n",
    "        rating = int(mRow['Rating'])\n",
    "        base = getBaseline(userId, int(mRow['MovieId']), matrix, matrixT, avgGlobal)\n",
    "        top += sim * (rating - base)\n",
    "    print(time.time() - start)\n",
    "    return (top / bot)\n",
    "\n",
    "avgGlobal = np.extract(ratingMatrix > 0, ratingMatrix).mean()\n",
    "\n",
    "print(getBaseline(363, 97, ratingMatrix, ratingMatrixT, avgGlobal) + \n",
    "      localRating(363, 97, ratings_df, ratingMatrix, ratingMatrixT, avgGlobal, 10, cosine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.930120122143846\n"
     ]
    }
   ],
   "source": [
    "def localRatingCutoff(userId, movieId, ratingsDf, matrix, matrixT, avgGlobal, cutoff, similarityFunc):\n",
    "    top = 0\n",
    "    bot = 0\n",
    "    simItems = itemItemAboveCutoff(userId, movieId, cutoff, matrix, matrixT, similarityFunc)\n",
    "    def topCalc(row):\n",
    "        rowMovieId = row[0]\n",
    "        sim = row[1]\n",
    "        rating = row[2]\n",
    "        baseline = getBaseline(userId, int(rowMovieId), matrix, matrixT, avgGlobal)\n",
    "        return sim * (rating - baseline)\n",
    "    if(len(simItems) is 0):\n",
    "        return 0\n",
    "    top = np.apply_along_axis(topCalc, 1, simItems).sum()\n",
    "    bot = simItems[:,1].sum()\n",
    "    if(bot is 0):\n",
    "        return 0\n",
    "    \n",
    "    return (top / bot)\n",
    "\n",
    "print(getBaseline(363, 97, ratingMatrix, ratingMatrixT, avgGlobal) + \n",
    "      localRatingCutoff(363, 97, ratings_df, ratingMatrix, ratingMatrixT, avgGlobal, .5, jaccard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Putting it all together! [20 points]\n",
    "\n",
    "Finally, we're going to experiment with our different methods to see which one performs the best on our special test set of \"hidden\" ratings. We have three big \"kinds\" of recommenders:\n",
    "\n",
    "* User-User Collaborative Filtering\n",
    "* Baseline Recommendation (Global)\n",
    "* Local + Global Recommender\n",
    "\n",
    "\n",
    "But within each, we have lots of design choices. For example, do we try Jaccard+Average or Jaccard+WeightedAverage1? Do we try Jaccard or Cosine or Pearson? What choice of k? Etc.\n",
    "\n",
    "For this part, you should train your methods on a special train set (the base set, see below). Then report your results over the test set (see below). You should use RMSE as your metric of choice. Which method performs best? You will need to experiment with many different approaches, but ultimately, you should tell us the best 2 or 3 methods and report the RMSE you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('ua.base', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n",
    "test = pd.read_csv('ua.test', sep='\\t', names=['UserId', 'MovieId', 'Rating'],usecols=range(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1683\n"
     ]
    }
   ],
   "source": [
    "trainingRatingMatrix= getRatingMatrix(train)\n",
    "trainingRatingMatrixT = trainingRatingMatrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def GetRMSE(testDf, predictionFunction):\n",
    "    rmse = 0\n",
    "    cnt = 0\n",
    "    for index, row in testDf.iterrows():\n",
    "        start = time.time()\n",
    "        score = predictionFunction(row)\n",
    "        if(math.isnan(score)):\n",
    "            score = 0\n",
    "        sqrDiff = math.pow(row['Rating'] - score, 2)\n",
    "        rmse += sqrDiff\n",
    "        cnt+=1\n",
    "    return math.sqrt(rmse/cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryanc\\Anaconda3\\envs\\newcs470\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "C:\\Users\\ryanc\\Anaconda3\\envs\\newcs470\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9931349305268995"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline\n",
    "avgGlobal = np.extract(trainingRatingMatrix > 0, trainingRatingMatrix).mean()\n",
    "def baselinePrediction(row):\n",
    "    return getBaseline(row['UserId'], row['MovieId'], trainingRatingMatrix, trainingRatingMatrixT, avgGlobal)\n",
    "\n",
    "GetRMSE(test, baselinePrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRMSE(testDf, predictionFunction, k, simFunc, simFuncName):\n",
    "    rmse = 0\n",
    "    cnt = 0\n",
    "    for index, row in testDf.iterrows():\n",
    "        start = time.time()\n",
    "        score = predictionFunction(row, k, simFunc)\n",
    "        if(math.isnan(score)):\n",
    "            score = 0\n",
    "        sqrDiff = math.pow(row['Rating'] - score, 2)\n",
    "        #if(sqrDiff > 2):\n",
    "        #    print(row, score)\n",
    "        rmse += sqrDiff\n",
    "        cnt+=1\n",
    "        \n",
    "    return {'k': k, 'similarityFunc': simFuncName, 'error' : math.sqrt(rmse/cnt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = 8\n",
    "\n",
    "def ParallelRMSE(testDf, predictionFunction, predictionFunctionName, ks, simFuncs):\n",
    "    allPairs = [ (k,name,func) for k in ks for name, func in simFuncs.items()]\n",
    "    results = Parallel(n_jobs=num_cores)(delayed(GetRMSE)(testDf,predictionFunction,k,func, name) for (k,name,func) in allPairs)\n",
    "    error_df = pd.DataFrame(data=results)\n",
    "    error_df['predictionFunction'] = predictionFunctionName\n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicAverageUserUser(row, k, simFunc):\n",
    "    return getClosestkSimilarUsers(\n",
    "        row['MovieId'],\n",
    "        row['UserId'],\n",
    "        simFunc, \n",
    "        k, \n",
    "        trainingRatingMatrix, \n",
    "        trainingRatingMatrixT)['Rating'].mean()\n",
    "ks = [5,10,15,25]\n",
    "similarityFuncs = {'jaccard' : jaccard,'cosine' : cosine,'pearson' : pearson}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>k</th>\n",
       "      <th>similarityFunc</th>\n",
       "      <th>predictionFunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.093451</td>\n",
       "      <td>5</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.084647</td>\n",
       "      <td>5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.093668</td>\n",
       "      <td>5</td>\n",
       "      <td>pearson</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.054784</td>\n",
       "      <td>10</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.049169</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.055389</td>\n",
       "      <td>10</td>\n",
       "      <td>pearson</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.043985</td>\n",
       "      <td>15</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.038396</td>\n",
       "      <td>15</td>\n",
       "      <td>cosine</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.043707</td>\n",
       "      <td>15</td>\n",
       "      <td>pearson</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.036946</td>\n",
       "      <td>25</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.031459</td>\n",
       "      <td>25</td>\n",
       "      <td>cosine</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.034400</td>\n",
       "      <td>25</td>\n",
       "      <td>pearson</td>\n",
       "      <td>basicAverageUserUser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error   k similarityFunc    predictionFunction\n",
       "0   1.093451   5        jaccard  basicAverageUserUser\n",
       "1   1.084647   5         cosine  basicAverageUserUser\n",
       "2   1.093668   5        pearson  basicAverageUserUser\n",
       "3   1.054784  10        jaccard  basicAverageUserUser\n",
       "4   1.049169  10         cosine  basicAverageUserUser\n",
       "5   1.055389  10        pearson  basicAverageUserUser\n",
       "6   1.043985  15        jaccard  basicAverageUserUser\n",
       "7   1.038396  15         cosine  basicAverageUserUser\n",
       "8   1.043707  15        pearson  basicAverageUserUser\n",
       "9   1.036946  25        jaccard  basicAverageUserUser\n",
       "10  1.031459  25         cosine  basicAverageUserUser\n",
       "11  1.034400  25        pearson  basicAverageUserUser"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParallelRMSE(test, basicAverageUserUser, \"basicAverageUserUser\", ks, similarityFuncs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user user\n",
    "def userUserWeightedAverage1Prediction(row, k, simFunc):\n",
    "    #if we havent observed any rankings for this guy return global avg\n",
    "    if(len(train[train.MovieId == row['MovieId']]) == 0):\n",
    "        return avgGlobal\n",
    "    score = weightedAverage(row['MovieId'], row['UserId'], simFunc, k, trainingRatingMatrix, trainingRatingMatrixT)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>k</th>\n",
       "      <th>similarityFunc</th>\n",
       "      <th>predictionFunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.092170</td>\n",
       "      <td>5</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.083332</td>\n",
       "      <td>5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.166313</td>\n",
       "      <td>5</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.053130</td>\n",
       "      <td>10</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.047697</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.195928</td>\n",
       "      <td>10</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.042133</td>\n",
       "      <td>15</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.037056</td>\n",
       "      <td>15</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.908938</td>\n",
       "      <td>15</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.034347</td>\n",
       "      <td>25</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.029403</td>\n",
       "      <td>25</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.122827</td>\n",
       "      <td>25</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage1Prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error   k similarityFunc                  predictionFunction\n",
       "0   1.092170   5        jaccard  userUserWeightedAverage1Prediction\n",
       "1   1.083332   5         cosine  userUserWeightedAverage1Prediction\n",
       "2   1.166313   5        pearson  userUserWeightedAverage1Prediction\n",
       "3   1.053130  10        jaccard  userUserWeightedAverage1Prediction\n",
       "4   1.047697  10         cosine  userUserWeightedAverage1Prediction\n",
       "5   1.195928  10        pearson  userUserWeightedAverage1Prediction\n",
       "6   1.042133  15        jaccard  userUserWeightedAverage1Prediction\n",
       "7   1.037056  15         cosine  userUserWeightedAverage1Prediction\n",
       "8   1.908938  15        pearson  userUserWeightedAverage1Prediction\n",
       "9   1.034347  25        jaccard  userUserWeightedAverage1Prediction\n",
       "10  1.029403  25         cosine  userUserWeightedAverage1Prediction\n",
       "11  2.122827  25        pearson  userUserWeightedAverage1Prediction"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParallelRMSE(test, userUserWeightedAverage1Prediction, \"userUserWeightedAverage1Prediction\", ks, similarityFuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user user2\n",
    "def userUserWeightedAverage2Prediction(row, k, simFunc):\n",
    "    #if we havent observed any rankings for this guy return global avg\n",
    "    if(len(train[train.MovieId == row['MovieId']]) == 0):\n",
    "        return avgGlobal\n",
    "    return weightedAverage2(row['MovieId'], row['UserId'], simFunc, k,trainingRatingMatrix, trainingRatingMatrixT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>k</th>\n",
       "      <th>similarityFunc</th>\n",
       "      <th>predictionFunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.024510</td>\n",
       "      <td>5</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.014063</td>\n",
       "      <td>5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.071685</td>\n",
       "      <td>5</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985823</td>\n",
       "      <td>10</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984099</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.118614</td>\n",
       "      <td>10</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974632</td>\n",
       "      <td>15</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.974912</td>\n",
       "      <td>15</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.245500</td>\n",
       "      <td>15</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.968277</td>\n",
       "      <td>25</td>\n",
       "      <td>jaccard</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.968860</td>\n",
       "      <td>25</td>\n",
       "      <td>cosine</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.448344</td>\n",
       "      <td>25</td>\n",
       "      <td>pearson</td>\n",
       "      <td>userUserWeightedAverage2Prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error   k similarityFunc                  predictionFunction\n",
       "0   1.024510   5        jaccard  userUserWeightedAverage2Prediction\n",
       "1   1.014063   5         cosine  userUserWeightedAverage2Prediction\n",
       "2   1.071685   5        pearson  userUserWeightedAverage2Prediction\n",
       "3   0.985823  10        jaccard  userUserWeightedAverage2Prediction\n",
       "4   0.984099  10         cosine  userUserWeightedAverage2Prediction\n",
       "5   1.118614  10        pearson  userUserWeightedAverage2Prediction\n",
       "6   0.974632  15        jaccard  userUserWeightedAverage2Prediction\n",
       "7   0.974912  15         cosine  userUserWeightedAverage2Prediction\n",
       "8   1.245500  15        pearson  userUserWeightedAverage2Prediction\n",
       "9   0.968277  25        jaccard  userUserWeightedAverage2Prediction\n",
       "10  0.968860  25         cosine  userUserWeightedAverage2Prediction\n",
       "11  1.448344  25        pearson  userUserWeightedAverage2Prediction"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParallelRMSE(test, userUserWeightedAverage2Prediction, \"userUserWeightedAverage2Prediction\", ks, similarityFuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local + global\n",
    "def localPlusGlobalPrediction(row, k, simFunc):\n",
    "    base = getBaseline(row['UserId'], row['MovieId'], trainingRatingMatrix, trainingRatingMatrixT, avgGlobal)\n",
    "    local = localRating(row['UserId'], row['MovieId'], train, trainingRatingMatrix, trainingRatingMatrixT, avgGlobal, k, simFunc)\n",
    "    return local + base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParallelRMSE(test, localPlusGlobalPrediction, \"localPlusGlobalPrediction\", ks, similarityFuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(getBaseline(363, 97, ratingMatrix, ratingMatrixT, avgGlobal) + \n",
    "#      localRatingCutoff(363, 97, ratings_df, ratingMatrix, ratingMatrixT, avgGlobal, .25, pearson))\n",
    "\n",
    "def localPlusGlobalPredictionCutoff(row, cutoff, simFunc):\n",
    "    base = getBaseline(row['UserId'], row['MovieId'], trainingRatingMatrix, trainingRatingMatrixT, avgGlobal)\n",
    "    local = localRatingCutoff(row['UserId'], row['MovieId'], train, trainingRatingMatrix, trainingRatingMatrixT, avgGlobal, cutoff, simFunc)\n",
    "    return local + base\n",
    "\n",
    "cutoffs = [.05, .1, .15, .2, .3, .4, .5, .6, .7]\n",
    "\n",
    "ParallelRMSE(test, localPlusGlobalPredictionCutoff, \"localPlusGlobalPredictionCutoff\", cutoffs, similarityFuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [.7, .8, .9, .95]\n",
    "similarityFuncs = {'pearson' : pearson}\n",
    "ParallelRMSE(test, localPlusGlobalPredictionCutoff, \"localPlusGlobalPredictionCutoff\", cutoffs, similarityFuncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*provide your best 2 or 3 methods, their RMSE, plus some discussion of why they did the best*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best method I found was the local plus global function using the jaccard or cosine similarity with a k of 25. This acheived a RMSE of .944 which was .05 better than the base line result (.993). this one probably did better than the rest because it was centered around the global baseline and made incremental improvment where it could. The pearson similarity function seemed to perform badly in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: \n",
    "Can you do better? Find a way to improve the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
